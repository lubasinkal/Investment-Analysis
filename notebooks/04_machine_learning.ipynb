{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model Implementation and Evaluation\n",
    "## 1. Introduction\n",
    "\n",
    "In this notebook, we implemented and evaluated two machine learning models—Linear Regression and Random Forest Regressor—to predict the next day's closing price of a selected stock. The primary goal was to compare the performance of these models using various evaluation metrics and cross-validation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MA_30</th>\n",
       "      <th>MA_100</th>\n",
       "      <th>Daily Returns</th>\n",
       "      <th>Log Returns</th>\n",
       "      <th>Cumulative Log Returns</th>\n",
       "      <th>Cumulative Returns</th>\n",
       "      <th>Cumulative Percentage Return</th>\n",
       "      <th>Rolling Mean</th>\n",
       "      <th>Rolling Std</th>\n",
       "      <th>Volatility 30</th>\n",
       "      <th>Volatility 100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0.936384</td>\n",
       "      <td>1.004464</td>\n",
       "      <td>0.907924</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.844981</td>\n",
       "      <td>535796800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.987723</td>\n",
       "      <td>0.903460</td>\n",
       "      <td>0.915179</td>\n",
       "      <td>0.773741</td>\n",
       "      <td>512377600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.084310</td>\n",
       "      <td>-0.088077</td>\n",
       "      <td>-0.088077</td>\n",
       "      <td>-0.084310</td>\n",
       "      <td>-8.431001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0.926339</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.785063</td>\n",
       "      <td>778321600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.014527</td>\n",
       "      <td>-0.073550</td>\n",
       "      <td>-0.070911</td>\n",
       "      <td>-7.091056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>0.947545</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.717125</td>\n",
       "      <td>767972800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.086538</td>\n",
       "      <td>-0.090514</td>\n",
       "      <td>-0.164064</td>\n",
       "      <td>-0.151312</td>\n",
       "      <td>-15.131245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.852679</td>\n",
       "      <td>0.888393</td>\n",
       "      <td>0.751094</td>\n",
       "      <td>460734400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047369</td>\n",
       "      <td>0.046281</td>\n",
       "      <td>-0.117783</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-11.111100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date      Open      High       Low     Close  Adj Close  \\\n",
       "0           0  2000-01-03  0.936384  1.004464  0.907924  0.999442   0.844981   \n",
       "1           1  2000-01-04  0.966518  0.987723  0.903460  0.915179   0.773741   \n",
       "2           2  2000-01-05  0.926339  0.987165  0.919643  0.928571   0.785063   \n",
       "3           3  2000-01-06  0.947545  0.955357  0.848214  0.848214   0.717125   \n",
       "4           4  2000-01-07  0.861607  0.901786  0.852679  0.888393   0.751094   \n",
       "\n",
       "      Volume  MA_30  MA_100  Daily Returns  Log Returns  \\\n",
       "0  535796800    NaN     NaN            NaN          NaN   \n",
       "1  512377600    NaN     NaN      -0.084310    -0.088077   \n",
       "2  778321600    NaN     NaN       0.014633     0.014527   \n",
       "3  767972800    NaN     NaN      -0.086538    -0.090514   \n",
       "4  460734400    NaN     NaN       0.047369     0.046281   \n",
       "\n",
       "   Cumulative Log Returns  Cumulative Returns  Cumulative Percentage Return  \\\n",
       "0                     NaN                 NaN                           NaN   \n",
       "1               -0.088077           -0.084310                     -8.431001   \n",
       "2               -0.073550           -0.070911                     -7.091056   \n",
       "3               -0.164064           -0.151312                    -15.131245   \n",
       "4               -0.117783           -0.111111                    -11.111100   \n",
       "\n",
       "   Rolling Mean  Rolling Std  Volatility 30  Volatility 100  \n",
       "0           NaN          NaN            NaN             NaN  \n",
       "1           NaN          NaN            NaN             NaN  \n",
       "2           NaN          NaN            NaN             NaN  \n",
       "3           NaN          NaN            NaN             NaN  \n",
       "4           NaN          NaN            NaN             NaN  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_path = os.listdir(\"../data/processed/market data/\")\n",
    "data = pd.read_csv(f\"../data/processed/market data/{file_path[0]}\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Target Variable Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target variable\n",
    "data.dropna(inplace=True)\n",
    "X = data[['Open', 'High', 'Low', 'Volume', 'MA_30', 'MA_100', 'Volatility 30', 'Volatility 100', 'Rolling Std']]\n",
    "y = data['Close'].shift(-1).dropna()\n",
    "X = X.iloc[:-1]  # Align X with y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We selected specific features from the dataset that are likely to influence the stock’s closing price. The target variable y is the closing price shifted by one day, which allows the models to learn and predict the next day's price based on the current day’s features. Aligning X and y ensures that the lengths of our feature set and target variable match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression and Random Forest models\n",
    "model = LinearRegression()\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results:\n",
      "Mean Squared Error: 1.6803818038862606\n",
      "R-squared: 0.999461407610897\n",
      "Mean Absolute Error: 0.5595357140026218\n",
      "Explained Variance Score: 0.9994618876988046\n",
      "\n",
      "Random Forest Results:\n",
      "Mean Squared Error: 1.8963888094472183\n",
      "R-squared: 0.9993921735065291\n",
      "Mean Absolute Error: 0.6074940994073352\n",
      "Explained Variance Score: 0.9993924256488199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "# Evaluate models\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "evs_rf = explained_variance_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Explained Variance Score: {evs}\\n\")\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Mean Squared Error: {mse_rf}\")\n",
    "print(f\"R-squared: {r2_rf}\")\n",
    "print(f\"Mean Absolute Error: {mae_rf}\")\n",
    "print(f\"Explained Variance Score: {evs_rf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluated the models using Mean Squared Error (MSE), R-squared, Mean Absolute Error (MAE), and Explained Variance Score. These metrics provide insight into how well the models perform, with a particular focus on error magnitude and the proportion of variance explained by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated MSE Scores Linear Regression: [3.92362516e-02 7.94197211e-04 5.38546126e-03 2.20652034e-02\n",
      " 6.32716973e-02 1.15627701e-01 1.90378676e-01 6.20210583e-01\n",
      " 5.61834984e+00 9.37999850e+00]\n",
      "Cross-Validated MSE Scores Random Forest: [2.24063258e-02 2.05822152e-02 9.02179240e-02 2.10732683e-01\n",
      " 2.49950029e+00 1.05475811e+00 1.26737952e+00 2.65679644e+01\n",
      " 1.45778039e+02 1.95644960e+02]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = -cross_val_score(model, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "cv_scores_rf = -cross_val_score(rf_model, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(\"Cross-Validated MSE Scores Linear Regression:\", cv_scores)\n",
    "print(\"Cross-Validated MSE Scores Random Forest:\", cv_scores_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the robustness of our models, we performed 10-fold cross-validation. This method helps in assessing how the model will generalize to an independent dataset, reducing the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### Linear Regression:\n",
    "\n",
    "Performance: The Linear Regression model performed exceptionally well on the test data, achieving high R-squared and low MSE and MAE values.\n",
    "Cross-Validation: Cross-validation results showed variability in model performance across different folds, indicating potential overfitting or sensitivity to data splits.\n",
    "\n",
    "### Random Forest:\n",
    "\n",
    "Performance: The Random Forest model also performed well, though slightly less accurately than the Linear Regression model in this case.\n",
    "Cross-Validation: The cross-validation scores exhibited higher variance compared to Linear Regression, which might be due to the Random Forest's reliance on specific feature combinations.\n",
    "\n",
    "### Final Thoughts:\n",
    "\n",
    "Both models demonstrated strong predictive performance, but the Linear Regression model slightly outperformed the Random Forest in this specific case. However, it's essential to consider the use case and data characteristics when choosing between these models. In scenarios with more complex, non-linear relationships, Random Forest may outperform Linear Regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
